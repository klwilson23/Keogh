"kalman.rw" <- function(init.mean.a, init.var.a, b, ln.sig.e, ln.sig.w, x, y, Ts = 0)
{

#
# Written for S-Plus 2000, Professional Release 2
# Source of this code:
# School of Resource and Environmental Management
# Simon Fraser University
# Burnaby, British Columbia
# Canada V5A 1S6
#
# For future inquiries, contact:
# Randall M. Peterman at the above School, either by
#       e-mail at rmpasst@sfu.ca or by phone at 604 291-4683
#
# Authors of this code:
# Brice MacGregor
# February 14, 2001
# Modified by Brian to handle missing data by using one-step-ahead forecasts, Oct. 10, 2002

# Version Features:
# - Simple linear regression
# - Time-varying intercept only
# - Intercept follows a random walk

# Purpose:
# ========
# Performs recursive calculations for simple Kalman filter model with a time-varying
# intercept parameter which follows a random walk.  Calculates the concentrated
# likelihood function given the data, starting values for the mean and variance of
# the intercept, and parameter values.  This function is used with the S-Plus function
# "ms" to find the maximum likelihood estimates for the parameters.
# Observation Equation:  y(t) = a(t) + b*x(t) + e(t)
# System Equation:   a(t) = a(t-1) + w(t)
# where:  v(t)~N(0,sig.e^2), w(t)~N(0,sig.w^2)

# Arguments:
# ========================
# init.mean.a  Starting mean for intercept
# init.var.a  Starting variance for intercept
# b     Slope parameter
# ln.sig.e   Natural log of the standard deviation of observation error*
# ln.sig.w   Natural log of the standard deviation of system error*
# x     Independent variable in obs. equation 
# y     Dependent variable in obs. equation
# Ts    Number of years to omit when calculating the concentrated likelihood
#     for the data set. See Visser and Molenaar (1988).  Default is zero.
# *The natural log for the standard deviations of noise terms are used as inputs rather
# than the straight standard deviations to ensure that the maximum likelihood procedure
# only returns values that are greater than or equal to 1.  The function returns
# the straight standard deviations in the output.

	# Calculate standard deviations for noise terms
	sig.e <- exp(ln.sig.e)
	sig.w <- exp(ln.sig.w)	
	
	# Length of time series
	Tmax <- length(x)	
	
	# Create vectors to store values calculated each year
	prior.mean.a <- rep(NA, Tmax)	# Prior mean of intercept (a)
	prior.var.a <- rep(NA, Tmax)	# Prior variance of intercept (a)
	y.hat <- rep(NA, Tmax)			# Predicted value of y(t) given y(t-1)
	f <- rep(NA, Tmax)				# Prediction variance
	v <- rep(NA, Tmax)				# Prediction error
	post.mean.a <- rep(NA, Tmax)	# Posterior mean of intercept (a)
	post.var.a <- rep(NA, Tmax)	# Posterior variance of intercept (a)
	filter.y <- rep(NA, Tmax)		# Filtered value for y
	neg.log.like <- rep(NA, Tmax)	# Negative log-likelihood - MIN to get ML estimates
	p.star <- rep(NA, Tmax)			# Used in smoothing
	smoothe.mean.a <- rep(NA, Tmax)	# Smoothed mean of intercept (a)
	smoothe.var.a <- rep(NA, Tmax)	# Smoothed variance of intercept (a)
	smoothe.y <- rep(NA, Tmax)		# Smoothed y
	
	# Start loop over time for recursive calculations:

	#Brian $$$$$$$
	cum.neg.log.lik <- 0
	
	for(t in 1:Tmax) 
	{
		# Step 1: Calculate prior mean and variance of intercept (a)
		#   If t=1, then initial values are used as posteriors from previous period
		#   Else, posteriors from previous period are used

		if(t == 1) 
		{
			prior.mean.a[t] <- init.mean.a
			prior.var.a[t] <- init.var.a
		}
		else 
		{
			prior.mean.a[t] <- post.mean.a[t - 1]
			prior.var.a[t] <- post.var.a[t - 1] + sig.w^2
		}
		
		if(is.na(x[t]) == T) 
		{
			# Step 2: Predict next value for a[t]
			#y.hat[t] <- prior.mean.a[t] + b * x[t]
			#v[t] <- y[t] - y.hat[t]
			#f[t] <- prior.var.a[t] + sig.e^2

			# Step 3: Generate posterior distribution for intercept (a):
			post.mean.a[t] <- prior.mean.a[t]
			post.var.a[t] <- prior.var.a[t]	
			#filter.y[t] <- post.mean.a[t] + b * x[t]

			# Step 4: Calculate the concentrated likelihood function:
			neg.log.like[t] <- 0
		}
		
		else 
		{
			# Step 2: Generate predicted value for y(t) given y(t-1) and error
			y.hat[t] <- prior.mean.a[t] + b * x[t]
			v[t] <- y[t] - y.hat[t]
			f[t] <- prior.var.a[t] + sig.e^2	
	
			# Step 3: Generate posterior distribution for intercept (a):
			post.mean.a[t] <- prior.mean.a[t] + (prior.var.a[t] * (v[t]/f[t]))
			post.var.a[t] <- prior.var.a[t] - (prior.var.a[t]^2/f[t])
			filter.y[t] <- post.mean.a[t] + b * x[t]
			neg.log.like[t] <- (log(f[t]) + (v[t]^2/f[t]))/2
		}
	} # End loop over time
	
	# Step 5: Calculate cumulative value for concentrated negative log-likelihood 
	assign("sub1", Ts + 1, where = 0)
	assign("sub2", Tmax, where = 0)
	cum.neg.log.lik <- sum(neg.log.like[sub1:sub2])	
	
	# Step 6: Smoothing of kalman filter estimates for time-varying intercept
	# Start loop over time (NB: Calculations start with last values first)
	for(t in Tmax:1) 
	{
		if(t == Tmax) 
		{
			p.star[t] <- NA
			smoothe.mean.a[t] <- post.mean.a[t]
			smoothe.var.a[t] <- post.var.a[t]
		}

		else 
		{
			p.star[t] <- post.var.a[t]/prior.var.a[t + 1]
			smoothe.mean.a[t] <- post.mean.a[t] + p.star[t] * (smoothe.mean.a[t + 1] - prior.mean.a[t + 1])
			smoothe.var.a[t] <- post.var.a[t] + p.star[t]^2 * (smoothe.var.a[t + 1] - prior.var.a[t + 1])
		}
		
		smoothe.y[t] <- smoothe.mean.a[t] + b * x[t]

	} # End loop over time

	# Create a list to store output
	# =============================

	# Lines to put output in appropriate format
	init.mean.a <- as.vector(init.mean.a)
	init.var.a <- as.vector(init.var.a)
	b <- as.vector(b)
	sig.e <- as.vector(sig.e)
	sig.w <- as.vector(sig.w)
	out <- list(x = x, y = y, prior.mean.a = prior.mean.a, 
		prior.var.a = prior.var.a, y.hat = y.hat, f = f, v = v, 
		post.mean.a = post.mean.a, post.var.a = post.var.a, 
		filter.y = filter.y, neg.log.like = neg.log.like, 
		p.star = p.star, smoothe.mean.a = smoothe.mean.a, 
		smoothe.var.a = smoothe.var.a, smoothe.y = smoothe.y, 
		cum.neg.log.lik = cum.neg.log.lik, init.mean.a = 
		init.mean.a, init.var.a = init.var.a, a.bar = NA, b = b,
		sig.e = sig.e, sig.w = sig.w, rho = NA)
	out
}
